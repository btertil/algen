{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center; font-size: 2.5em; padding: 30px;\">Weryfikacja mojego algorytmu Algen</h1>\n",
    "<h4 style=\"color: gray;\">\n",
    "\n",
    "\n",
    "Podejście:<br>\n",
    "<ol>\n",
    "    <li> Obliczenie współczynników za pomocą regresji liniowej z pakietu scikit-learn\n",
    "    <li> Obliczenie współczynników za pomocą macierzy pseudo-inwersji Moore'a-Penrose'a\n",
    "    </ol>\n",
    "</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Metoda regresji liniowej z scikit-learn \n",
    "\n",
    "Tu wykorzystałem pandas do wczytania danych z CSV (większy plik).<br>\n",
    "Następnie standardowo <b>sklearn.linear_model.LinearRegression</b> oraz <b>sklearn.metrics.mean_squared_error</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    algen_data = pd.read_csv(\"algen_data.csv\", names = [\"target\", \"a\", \"b\"])\n",
    "    print(\"Dane zostały poprawnie wczytane. \\nShape algen_data to: %s\" % str(algen_data.shape))\n",
    "except:\n",
    "    print(\"Nie udało się wczytać danych, sprawdź lolalizację pliku z danymi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algen_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = algen_data[[\"a\", \"b\"]]\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = algen_data[['target']]\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zmienna a\n",
    "np.array(X)[:, :1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zmienna b\n",
    "np.array(X)[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=[16, 6])\n",
    "\n",
    "ax[0].hist(X.values[:, :1], bins=20, color=\"cornflowerblue\")\n",
    "ax[0].set_ylim(0, 300)\n",
    "ax[0].set_xlim(0, 900)\n",
    "ax[0].set_title(\"Histogram of Variable a\", fontsize=\"15\")\n",
    "ax[0].grid(True)\n",
    "\n",
    "ax[1].hist(X.values[:, 1:], bins=20, color=\"cornflowerblue\")\n",
    "ax[1].set_ylim(0, 300)\n",
    "ax[1].set_xlim(0, 10500)\n",
    "ax[1].set_title(\"Histogram of Variable b\", fontsize=\"15\")\n",
    "ax[1].grid(True)\n",
    "\n",
    "ax[2].hist(y.values, bins=20, color=\"brown\")\n",
    "ax[2].set_ylim(0, 300)\n",
    "ax[2].set_xlim(0, 3500)\n",
    "ax[2].set_title(\"Histogram of Target variable (y)\", fontsize=\"15\")\n",
    "ax[2].grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=[16, 6])\n",
    "\n",
    "ax[0].plot(X.values[:, :1], y)\n",
    "ax[0].set_ylabel(\"Target\", fontsize=\"13\")\n",
    "ax[0].set_xlabel(\"Variable a\", fontsize=\"13\")\n",
    "ax[0].set_title(\"Target vs Variable a\", fontsize=\"15\")\n",
    "ax[0].grid(True)\n",
    "\n",
    "ax[1].plot(X.values[:, 1:], y)\n",
    "ax[1].set_ylabel(\"Target\", fontsize=\"13\")\n",
    "ax[1].set_xlabel(\"Variable b\", fontsize=\"13\")\n",
    "ax[1].set_title(\"Target vs Variable b\", fontsize=\"15\")\n",
    "ax[1].grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widać zmienna targetowa (y) jest wysyko skorelowana zarówno ze zmienną a jak i b:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wysoka korelacja między zmiennymi niezależnymi a i b\n",
    "pearsonr(X.values[:, :1], X.values[:, 1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Niestety, zmienne a i b są także wysoko skorelowane między sobą:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oraz między nimi i zmienną targetową\n",
    "pearsonr(X.values[:, :1], y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na razie to zignoruję, chcę zobaczyc jak regresja sobie z tym poradzi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression().fit(X, y)\n",
    "\n",
    "print(\"Regresja liniowa wyestymowała następujące wagi: \\nWa = %s, \\nWb = %s, \\nIntercept = %s\"\n",
    "      % (str(lm.coef_[0][0]), str(lm.coef_[0][1]), str(lm.intercept_[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R square = %.16f\" % lm.score(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = lm.predict(X)\n",
    "MSE = mean_squared_error(y_true = y, y_pred = y_prediction)\n",
    "RMSE = sqrt(MSE)\n",
    "\n",
    "print(\"MSE = %s, RMSE = %s\" % (MSE, RMSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rozkład reszt i wykresy błędów w zależności od wartości przewidywanej:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = (y_prediction - y).values\n",
    "SE = errors**2\n",
    "SE.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = errors.mean()\n",
    "sigma = errors.std()\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=[16, 6])\n",
    "\n",
    "n, bins, patches = ax[0].hist(errors, bins=35, density=True, color=\"darkseagreen\")\n",
    "ax[0].plot(bins, 1/(sigma * np.sqrt(2 * np.pi)) *  np.exp( - (bins - mu)**2 / (2 * sigma**2) ), linewidth=2, color='r')\n",
    "ax[0].set_xlim(-0.50, 0.50)\n",
    "ax[0].set_ylim(0, 4.0)\n",
    "ax[0].set_title(r\"Distribution of residuals $N(\\mu=%.3f, \\sigma=%.3f)$\" % (mu, sigma), fontsize=\"15\")\n",
    "ax[0].set_xlabel(\"Residuals\", fontsize=\"13\")\n",
    "ax[0].grid(True)\n",
    "\n",
    "ax[1].plot(y_prediction, errors, color=\"darkseagreen\")\n",
    "ax[1].set_xlim(0, 3500)\n",
    "ax[1].set_xlabel(\"Predicted values\", fontsize=\"13\")\n",
    "ax[1].set_ylabel(\"Residuals\", fontsize=\"13\")\n",
    "ax[1].set_title(\"Residuals by predicted values (+/- 3 $\\sigma$)\", fontsize=\"15\")\n",
    "ax[1].axhline(y=errors.std()*3, linewidth=1, color='r', linestyle=\"--\")\n",
    "ax[1].axhline(y=-errors.std()*3, linewidth=1, color='r', linestyle=\"--\")\n",
    "ax[1].grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reszty, zdają się mieć rozkład normalny ze średnią i dominantą w okolicy zera. Nie widać żadnych zależności dla wartości reszt i predykcji (w całym zakresie predykcji reszty wyglądają na przypadkowe). Dobre dopasowanie modelu potwierdza także bardzo niska i nieistotna korelacja reszt z wartościami przewidywanymi: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearsonr(y_prediction, SE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Metoda z użyciem pseudoinwersji macierzy Moore'a-Penrose'a \n",
    "\n",
    "Na podstawie podstawowych operacji na macierzach / algebra liniowa:<br>\n",
    "Poniewarz macierz X ze zmiennymi niezależnymi nie jest prawidłową macierzą z punktu widzenia matematyki, nie będzie miała inwersji i nie można użyć standardowej metody do rozwiązania układu równań liniowych o postaci:\n",
    "$\\vec{y} = A^{-1} \\cdot \\vec{b}$. Ponieważ pseudoinwersja macierzy Moore'a-Penrose'a spełnia warunek $A \\cdot A^+ \\approx I$, to macierz $A^+$ będzie maksymalnie zbliżona do $A^{-1}$ co pozwoli obliczyć estymowany wektor współczynników kierunkowych regresji $\\hat{y} $ i będzie minimalizowała błąd. Zatem:\n",
    "\n",
    "$$\\hat{y} = A^{+} \\cdot \\vec{b}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Należy pamiętać, aby <b>dodać kolejną kolumnę z 1</b> - to będzie potrzebne aby obliczyć współczynnik dla Intercept, gdyż oryginalnie w macierzy A są tylko kolumny dla zmiennych a i b podczas gdy pełne równanie to:\n",
    "\n",
    "$$Target = Wa \\cdot zmienna\\_a + Wb \\cdot zmienna\\_b + 1 \\cdot Intercept$$\n",
    "\n",
    "I właśnie dla tego $1 \\cdot Intercept$ dodaję kolumnę jedynek.\n",
    "<br>Dla ułatwienia korzystam z np.ones() i pd.assign(nowa_zmienna = ....) a następnie konwertuję X do array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array(X.assign(intercept = np.ones(X.shape[0])))\n",
    "print(A[:5])\n",
    "print(\"Shape: %s\" % str(A.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_plus = np.linalg.pinv(A)\n",
    "#print(\"Macierz pseudoinwersji po przekształceniu: \\n %s\" % str(A_plus))\n",
    "A_plus.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Obliczenie współczynników w Python<br>\n",
    "macierz pseudoinwersji otrzymujemy za pomocą np.linalg.piv(A)\n",
    "Następnie obliczamy estymatory jako iloczyn macierzy A_plus i wektora ze zmienną target (tu oznaczenie b): $\\hat{y} = A^+ \\cdot \\vec{b}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_values = np.linalg.pinv(A).dot(y)\n",
    "estimator_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Oszacowania przy pomocy macierzy pseudoinwersji Moore'a i Penrose'a:\\nWa = %s, \\nWb = %s, \\nIntercept: %s\"\n",
    "      % (estimator_values[0], estimator_values[1], estimator_values[2]))\n",
    "print(\"\\nPonieważ współczynniki są te same co dała regresja liniowa, miary błędów również będą takie same:\")\n",
    "print(\"MSE = %s, RMSE = %s\" % (MSE, RMSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oraz najlepszy wynik dla algorytmu Algen:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: green;\">\n",
    "[*] Najlepsze dopasowanie to: WA = 0.0778, WB = 0.3269, intercept = 24.9667, mse = 0.0140, residual standard error = 0.1184<br>\n",
    "</span>\n",
    "Czyli algen całkiem nieźle \"odgadł\" prawdziwe współczynniki stosując ewolucyjne podejście i losowe mutacje najlepszych rozwiązań\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus: Singular Value Decomposition (SVD)\n",
    "\n",
    "Jako, że nie jest to macież kwadratowa, to nie można policzyć eigenvectors i eigenvalues jak przy macierzy korelacji na przykład. Dlatego SVD, co także daje podobne efekty: left singular matrix, singular value vector, right singular matrix:\n",
    "\n",
    "$$A = U \\cdot diag(d) \\cdot V^{-1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UWAGA!\n",
    "# W pythonie macierz V jest już odwrócona, więc przy obliczaniu spowrotem A nie trzeba jej odwracać! \n",
    "U, d, V = np.linalg.svd(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rekonstrukcja oryginalnej macierzy za pomocą wszystkich \"3 głównych składowych\"\n",
    "U[:, :3].dot(np.diag(d[:3])).dot(V[:3, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rekonstrukcja oryginalnej macierzy za pomocą tylko \"2 pierwszych głównych składowych\"\n",
    "U[:, :2].dot(np.diag(d[:2])).dot(V[:2, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "W sumie SVD jest wykorzystywane do obliczania nie tylko głównych składowych ale i do macierzy Moore'a Penrose'a (pseudo inwersja macierzy A):\n",
    "\n",
    "$$A^+ = V \\cdot D^+ \\cdot U^T$$\n",
    "\n",
    "\n",
    "Inny sposób, bez SVD ale <b>mniej dokładny</b> to:\n",
    "\n",
    "$$\n",
    "A^+ = (A^T \\cdot A)^{-1} \\cdot A^T\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Mniej dokłady sposób bez SVD wtym przypadku daje jednak takie same rezultaty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# W A mamy już columnę z 1\n",
    "A_plus2 = np.linalg.inv(A.T.dot(A)).dot(A.T)\n",
    "\n",
    "# Wynik (wektor)\n",
    "A_plus2.dot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.trace(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.det(A[:A.shape[1], :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.shape"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "tensorflow-gpu-ds",
   "language": "python",
   "name": "tensorflow-gpu-ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
